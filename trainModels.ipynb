{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout,BatchNormalization, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import ResNet50, VGG16, MobileNet, DenseNet121\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.regularizers import l2\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '/kaggle/input/comofod/CoMoFoD_small_v2'\n",
    "\n",
    "comofod_data = {'image_id': [],'image_path': [],'label': []}\n",
    "  \n",
    "for img in os.listdir(dir_path):\n",
    "    if 'F' in img:\n",
    "        temp_path = os.path.join(dir_path, img)\n",
    "        comofod_data['image_path'].append(temp_path)\n",
    "        comofod_data['label'].append('fake')\n",
    "        comofod_data['image_id'].append(img)\n",
    "    if 'O' in img:\n",
    "        temp_path = os.path.join(dir_path, img)\n",
    "        comofod_data['image_path'].append(temp_path)\n",
    "        comofod_data['label'].append('real')\n",
    "        comofod_data['image_id'].append(img)\n",
    "        \n",
    "label_encoder = LabelEncoder()\n",
    "comofod_data = pd.DataFrame(comofod_data)\n",
    "comofod_data['label'] = label_encoder.fit_transform(comofod_data['label'])\n",
    "comofod_data = comofod_data.sample(frac=1, random_state=random.seed(42)).reset_index(drop=True)\n",
    "comofod_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(comofod_data[['image_path', 'label']], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_eq = cv2.equalizeHist(img_gray)\n",
    "\n",
    "    img_denoised = cv2.fastNlMeansDenoising(img_eq, None, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "    img_color_corrected = cv2.cvtColor(img_denoised, cv2.COLOR_GRAY2BGR)\n",
    "    img_color_corrected = cv2.cvtColor(img_color_corrected, cv2.COLOR_BGR2HSV)\n",
    "    img_color_corrected[:, :, 1] = img_color_corrected[:, :, 1] * 1.2\n",
    "    img_color_corrected[:, :, 2] = img_color_corrected[:, :, 2] * 0.8\n",
    "    img_color_corrected = cv2.cvtColor(img_color_corrected, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return img_color_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, shuffle=True, augment=False):\n",
    "        self.image_paths = data['image_path'].tolist()\n",
    "        self.labels = to_categorical(data['label'].astype(np.int32).tolist())\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self._shuffle_data()\n",
    "\n",
    "    def _shuffle_data(self):\n",
    "        if self.shuffle:\n",
    "            indices = np.random.permutation(len(self.image_paths))\n",
    "            self.image_paths = [self.image_paths[i] for i in indices]\n",
    "            self.labels = self.labels[indices]\n",
    "\n",
    "    def _augment_image(self, img):\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "\n",
    "        img = datagen.random_transform(img)\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img = preprocess_image(self.image_paths[i])\n",
    "        if self.augment:\n",
    "            img = self._augment_image(img)\n",
    "\n",
    "        img = img.astype(np.float32)/255\n",
    "        label = self.labels[i]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self._shuffle_data()\n",
    "\n",
    "class Dataloader(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.dataset))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = [self.dataset[j] for j in range(start, stop)]\n",
    "\n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        input_img_batch = batch[0]\n",
    "        label_batch = batch[1]\n",
    "\n",
    "        return input_img_batch, label_batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train, shuffle = True, augment=True)\n",
    "train_dataloader = Dataloader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = Dataset(test)\n",
    "test_dataloader = Dataloader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Model\n",
    "\n",
    "vanillaModel = Sequential()\n",
    "vanillaModel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "vanillaModel.add(BatchNormalization())\n",
    "vanillaModel.add(MaxPooling2D((2, 2)))\n",
    "vanillaModel.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "vanillaModel.add(BatchNormalization())\n",
    "vanillaModel.add(MaxPooling2D((2, 2)))\n",
    "vanillaModel.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "vanillaModel.add(BatchNormalization())\n",
    "vanillaModel.add(MaxPooling2D((2, 2)))\n",
    "vanillaModel.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "vanillaModel.add(BatchNormalization())\n",
    "vanillaModel.add(MaxPooling2D((2, 2)))\n",
    "vanillaModel.add(GlobalAveragePooling2D())\n",
    "vanillaModel.add(Dense(256, activation='relu'))\n",
    "vanillaModel.add(BatchNormalization())\n",
    "vanillaModel.add(Dropout(0.5))\n",
    "vanillaModel.add(Dense(128, activation='relu'))\n",
    "vanillaModel.add(BatchNormalization())\n",
    "vanillaModel.add(Dropout(0.5))\n",
    "vanillaModel.add(Dense(64, activation='relu'))\n",
    "vanillaModel.add(BatchNormalization())\n",
    "vanillaModel.add(Dropout(0.5))\n",
    "vanillaModel.add(Dense(2, activation='softmax'))\n",
    "\n",
    "vanillaModel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "vanillaModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "learning_rate = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, min_lr=0.001)\n",
    "\n",
    "vanillaModel.fit(train_dataloader, validation_data=test_dataloader, epochs=25, callbacks=[early_stop, learning_rate])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanillaModel.save('vanillaModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 Model\n",
    "\n",
    "resnet = ResNet50(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n",
    "resNetModel = GlobalAveragePooling2D()(resnet.output)\n",
    "resNetModel = Dense(1024, activation='relu')(resNetModel)\n",
    "resNetModel = Dense(1024, activation='relu')(resNetModel)\n",
    "resNetModel = Dense(512, activation='relu')(resNetModel)\n",
    "output = Dense(2, activation='softmax')(resNetModel)\n",
    "\n",
    "resNetModel = Model(resnet.inputs, output)\n",
    "\n",
    "resNetModel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "resNetModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "learning_rate = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, min_lr=0.001)\n",
    "\n",
    "resNetModel.fit(train_dataloader, validation_data=test_dataloader, epochs=25, callbacks=[early_stop, learning_rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resNetModel.save('NewresNet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobilNet\n",
    "\n",
    "mobilenet = MobileNet(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "for layer in mobilenet.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "mobileNetModel = GlobalAveragePooling2D()(mobilenet.output)\n",
    "mobileNetModel = Dense(1024, activation='relu')(mobileNetModel)\n",
    "mobileNetModel = Dense(1024, activation='relu')(mobileNetModel)\n",
    "mobileNetModel = Dense(512, activation='relu')(mobileNetModel)\n",
    "output_mobile = Dense(2, activation='softmax')(mobileNetModel)\n",
    "\n",
    "mobilenetModel = Model(mobilenet.inputs, output_mobile)\n",
    "\n",
    "mobilenetModel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "mobilenetModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "learning_rate = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, min_lr=0.001)\n",
    "\n",
    "mobilenetModel.fit(train_dataloader, validation_data=test_dataloader, epochs=25, callbacks=[early_stop, learning_rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetModel.save('mobileNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vgg16\n",
    "\n",
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "vgg16Model = GlobalAveragePooling2D()(vgg16.output)\n",
    "vgg16Model = Dense(1024, activation='relu')(vgg16Model)\n",
    "vgg16Model = Dense(1024, activation='relu')(vgg16Model)\n",
    "vgg16Model = Dense(512, activation='relu')(vgg16Model)\n",
    "output_vgg16 = Dense(2, activation='softmax')(vgg16Model)\n",
    "\n",
    "vgg16Model = Model(vgg16.inputs, output_vgg16)\n",
    "\n",
    "vgg16Model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "vgg16Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "learning_rate = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, min_lr=0.001)\n",
    "\n",
    "vgg16Model.fit(train_dataloader, validation_data=test_dataloader, epochs=25, callbacks=[early_stop, learning_rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16Model.save('vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet 121\n",
    "\n",
    "denseNet = DenseNet121(input_shape=(256, 256, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "for layer in denseNet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "denseNetModel = denseNet.output\n",
    "denseNetModel = GlobalAveragePooling2D()(denseNetModel)\n",
    "denseNetModel = Dense(1024, activation='relu')(denseNetModel)\n",
    "denseNetModel = Dense(1024, activation='relu')(denseNetModel)\n",
    "denseNetModel = Dense(512, activation='relu')(denseNetModel)\n",
    "denseNetModel = BatchNormalization()(denseNetModel)\n",
    "denseNetModel = Dropout(0.5)(denseNetModel)\n",
    "\n",
    "output_layer = Dense(2, activation='softmax')(denseNetModel)\n",
    "\n",
    "denseNetModel = Model(inputs=denseNet.input, outputs=output_layer)\n",
    "\n",
    "denseNetModel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "denseNetModel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "learning_rate = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, min_lr=0.001)\n",
    "\n",
    "denseNetModel.fit(train_dataloader, validation_data=test_dataloader, epochs=25, callbacks=[early_stop, learning_rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNetModel.save('denseNetModel.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
